
[Executed at: Thu Apr 6 11:27:47 PDT 2023]

==================================================
Task 1 (python) runtime (ms), 153123
Task 1: 2.0 out of 2
==================================================
Task 2 (python) runtime (ms), 43227
Task 2.1: 2.0 out of 2
Task 2.2: 3.0 out of 3
==================================================

23/04/06 11:24:31 WARN Utils: Your hostname, ip-172-31-10-73 resolves to a loopback address: 127.0.0.1; using 172.31.10.73 instead (on interface ens5)
23/04/06 11:24:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
:: loading settings :: url = jar:file:/opt/spark/spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /home/ccc_v1_g_88669_38809/.ivy2/cache
The jars for the packages stored in: /home/ccc_v1_g_88669_38809/.ivy2/jars
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-5e21478b-fa68-457d-8f77-a6a654bf35ee;1.0
	confs: [default]
	found graphframes#graphframes;0.8.1-spark3.0-s_2.12 in spark-packages
	found org.slf4j#slf4j-api;1.7.16 in central
:: resolution report :: resolve 376ms :: artifacts dl 22ms
	:: modules in use:
	graphframes#graphframes;0.8.1-spark3.0-s_2.12 from spark-packages in [default]
	org.slf4j#slf4j-api;1.7.16 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-5e21478b-fa68-457d-8f77-a6a654bf35ee
	confs: [default]
	0 artifacts copied, 2 already retrieved (0kB/17ms)
23/04/06 11:24:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
23/04/06 11:24:34 INFO SparkContext: Running Spark version 3.1.2
23/04/06 11:24:34 INFO ResourceUtils: ==============================================================
23/04/06 11:24:34 INFO ResourceUtils: No custom resources configured for spark.driver.
23/04/06 11:24:34 INFO ResourceUtils: ==============================================================
23/04/06 11:24:34 INFO SparkContext: Submitted application: task1.py
23/04/06 11:24:34 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/04/06 11:24:34 INFO ResourceProfile: Limiting resource is cpu
23/04/06 11:24:34 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/04/06 11:24:34 INFO SecurityManager: Changing view acls to: ccc_v1_g_88669_38809
23/04/06 11:24:34 INFO SecurityManager: Changing modify acls to: ccc_v1_g_88669_38809
23/04/06 11:24:34 INFO SecurityManager: Changing view acls groups to: 
23/04/06 11:24:34 INFO SecurityManager: Changing modify acls groups to: 
23/04/06 11:24:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ccc_v1_g_88669_38809); groups with view permissions: Set(); users  with modify permissions: Set(ccc_v1_g_88669_38809); groups with modify permissions: Set()
23/04/06 11:24:35 INFO Utils: Successfully started service 'sparkDriver' on port 35202.
23/04/06 11:24:35 INFO SparkEnv: Registering MapOutputTracker
23/04/06 11:24:35 INFO SparkEnv: Registering BlockManagerMaster
23/04/06 11:24:35 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/04/06 11:24:35 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/04/06 11:24:35 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/04/06 11:24:35 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-358a1eb2-4048-47a7-9084-60ecf53c7880
23/04/06 11:24:35 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/04/06 11:24:35 INFO SparkEnv: Registering OutputCommitCoordinator
23/04/06 11:24:35 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/04/06 11:24:35 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.31.10.73:4040
23/04/06 11:24:35 INFO SparkContext: Added JAR file:///home/ccc_v1_g_88669_38809/.ivy2/jars/graphframes_graphframes-0.8.1-spark3.0-s_2.12.jar at spark://172.31.10.73:35202/jars/graphframes_graphframes-0.8.1-spark3.0-s_2.12.jar with timestamp 1680805474498
23/04/06 11:24:35 INFO SparkContext: Added JAR file:///home/ccc_v1_g_88669_38809/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at spark://172.31.10.73:35202/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1680805474498
23/04/06 11:24:35 INFO SparkContext: Added file file:///home/ccc_v1_g_88669_38809/.ivy2/jars/graphframes_graphframes-0.8.1-spark3.0-s_2.12.jar at file:///home/ccc_v1_g_88669_38809/.ivy2/jars/graphframes_graphframes-0.8.1-spark3.0-s_2.12.jar with timestamp 1680805474498
23/04/06 11:24:35 INFO Utils: Copying /home/ccc_v1_g_88669_38809/.ivy2/jars/graphframes_graphframes-0.8.1-spark3.0-s_2.12.jar to /tmp/spark-6b0a2bc2-cb67-4e4c-8ae5-930b58cf65c3/userFiles-c35f5247-c8ee-4463-a880-bd678e8a1fc3/graphframes_graphframes-0.8.1-spark3.0-s_2.12.jar
23/04/06 11:24:35 INFO SparkContext: Added file file:///home/ccc_v1_g_88669_38809/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar at file:///home/ccc_v1_g_88669_38809/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1680805474498
23/04/06 11:24:35 INFO Utils: Copying /home/ccc_v1_g_88669_38809/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar to /tmp/spark-6b0a2bc2-cb67-4e4c-8ae5-930b58cf65c3/userFiles-c35f5247-c8ee-4463-a880-bd678e8a1fc3/org.slf4j_slf4j-api-1.7.16.jar
23/04/06 11:24:36 INFO Executor: Starting executor ID driver on host 172.31.10.73
23/04/06 11:24:36 INFO Executor: Fetching file:///home/ccc_v1_g_88669_38809/.ivy2/jars/graphframes_graphframes-0.8.1-spark3.0-s_2.12.jar with timestamp 1680805474498
23/04/06 11:24:36 INFO Utils: /home/ccc_v1_g_88669_38809/.ivy2/jars/graphframes_graphframes-0.8.1-spark3.0-s_2.12.jar has been previously copied to /tmp/spark-6b0a2bc2-cb67-4e4c-8ae5-930b58cf65c3/userFiles-c35f5247-c8ee-4463-a880-bd678e8a1fc3/graphframes_graphframes-0.8.1-spark3.0-s_2.12.jar
23/04/06 11:24:36 INFO Executor: Fetching file:///home/ccc_v1_g_88669_38809/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1680805474498
23/04/06 11:24:36 INFO Utils: /home/ccc_v1_g_88669_38809/.ivy2/jars/org.slf4j_slf4j-api-1.7.16.jar has been previously copied to /tmp/spark-6b0a2bc2-cb67-4e4c-8ae5-930b58cf65c3/userFiles-c35f5247-c8ee-4463-a880-bd678e8a1fc3/org.slf4j_slf4j-api-1.7.16.jar
23/04/06 11:24:36 INFO Executor: Fetching spark://172.31.10.73:35202/jars/org.slf4j_slf4j-api-1.7.16.jar with timestamp 1680805474498
23/04/06 11:24:36 INFO TransportClientFactory: Successfully created connection to /172.31.10.73:35202 after 67 ms (0 ms spent in bootstraps)
23/04/06 11:24:36 INFO Utils: Fetching spark://172.31.10.73:35202/jars/org.slf4j_slf4j-api-1.7.16.jar to /tmp/spark-6b0a2bc2-cb67-4e4c-8ae5-930b58cf65c3/userFiles-c35f5247-c8ee-4463-a880-bd678e8a1fc3/fetchFileTemp16926128092910558343.tmp
23/04/06 11:24:36 INFO Utils: /tmp/spark-6b0a2bc2-cb67-4e4c-8ae5-930b58cf65c3/userFiles-c35f5247-c8ee-4463-a880-bd678e8a1fc3/fetchFileTemp16926128092910558343.tmp has been previously copied to /tmp/spark-6b0a2bc2-cb67-4e4c-8ae5-930b58cf65c3/userFiles-c35f5247-c8ee-4463-a880-bd678e8a1fc3/org.slf4j_slf4j-api-1.7.16.jar
23/04/06 11:24:36 INFO Executor: Adding file:/tmp/spark-6b0a2bc2-cb67-4e4c-8ae5-930b58cf65c3/userFiles-c35f5247-c8ee-4463-a880-bd678e8a1fc3/org.slf4j_slf4j-api-1.7.16.jar to class loader
23/04/06 11:24:36 INFO Executor: Fetching spark://172.31.10.73:35202/jars/graphframes_graphframes-0.8.1-spark3.0-s_2.12.jar with timestamp 1680805474498
23/04/06 11:24:36 INFO Utils: Fetching spark://172.31.10.73:35202/jars/graphframes_graphframes-0.8.1-spark3.0-s_2.12.jar to /tmp/spark-6b0a2bc2-cb67-4e4c-8ae5-930b58cf65c3/userFiles-c35f5247-c8ee-4463-a880-bd678e8a1fc3/fetchFileTemp18093723880090079264.tmp
23/04/06 11:24:36 INFO Utils: /tmp/spark-6b0a2bc2-cb67-4e4c-8ae5-930b58cf65c3/userFiles-c35f5247-c8ee-4463-a880-bd678e8a1fc3/fetchFileTemp18093723880090079264.tmp has been previously copied to /tmp/spark-6b0a2bc2-cb67-4e4c-8ae5-930b58cf65c3/userFiles-c35f5247-c8ee-4463-a880-bd678e8a1fc3/graphframes_graphframes-0.8.1-spark3.0-s_2.12.jar
23/04/06 11:24:36 INFO Executor: Adding file:/tmp/spark-6b0a2bc2-cb67-4e4c-8ae5-930b58cf65c3/userFiles-c35f5247-c8ee-4463-a880-bd678e8a1fc3/graphframes_graphframes-0.8.1-spark3.0-s_2.12.jar to class loader
23/04/06 11:24:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42395.
23/04/06 11:24:36 INFO NettyBlockTransferService: Server created on 172.31.10.73:42395
23/04/06 11:24:36 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/04/06 11:24:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.31.10.73, 42395, None)
23/04/06 11:24:36 INFO BlockManagerMasterEndpoint: Registering block manager 172.31.10.73:42395 with 434.4 MiB RAM, BlockManagerId(driver, 172.31.10.73, 42395, None)
23/04/06 11:24:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.31.10.73, 42395, None)
23/04/06 11:24:36 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.31.10.73, 42395, None)
23/04/06 11:24:36 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/mnt/vocwork4/ccc_v1_g_88669_38809/asn1582479_7/asn1582480_1/2347494/19/work/spark-warehouse').
23/04/06 11:24:36 INFO SharedState: Warehouse path is 'file:/mnt/vocwork4/ccc_v1_g_88669_38809/asn1582479_7/asn1582480_1/2347494/19/work/spark-warehouse'.
2.0
23/04/06 11:27:03 WARN Utils: Your hostname, ip-172-31-10-73 resolves to a loopback address: 127.0.0.1; using 172.31.10.73 instead (on interface ens5)
23/04/06 11:27:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
23/04/06 11:27:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
23/04/06 11:27:04 INFO SparkContext: Running Spark version 3.1.2
23/04/06 11:27:04 INFO ResourceUtils: ==============================================================
23/04/06 11:27:04 INFO ResourceUtils: No custom resources configured for spark.driver.
23/04/06 11:27:04 INFO ResourceUtils: ==============================================================
23/04/06 11:27:04 INFO SparkContext: Submitted application: task2.py
23/04/06 11:27:04 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
23/04/06 11:27:04 INFO ResourceProfile: Limiting resource is cpu
23/04/06 11:27:04 INFO ResourceProfileManager: Added ResourceProfile id: 0
23/04/06 11:27:04 INFO SecurityManager: Changing view acls to: ccc_v1_g_88669_38809
23/04/06 11:27:04 INFO SecurityManager: Changing modify acls to: ccc_v1_g_88669_38809
23/04/06 11:27:04 INFO SecurityManager: Changing view acls groups to: 
23/04/06 11:27:04 INFO SecurityManager: Changing modify acls groups to: 
23/04/06 11:27:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ccc_v1_g_88669_38809); groups with view permissions: Set(); users  with modify permissions: Set(ccc_v1_g_88669_38809); groups with modify permissions: Set()
23/04/06 11:27:05 INFO Utils: Successfully started service 'sparkDriver' on port 43557.
23/04/06 11:27:05 INFO SparkEnv: Registering MapOutputTracker
23/04/06 11:27:05 INFO SparkEnv: Registering BlockManagerMaster
23/04/06 11:27:05 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
23/04/06 11:27:05 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
23/04/06 11:27:05 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
23/04/06 11:27:05 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-71827a88-084a-4608-b781-f430a48ec2d2
23/04/06 11:27:05 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
23/04/06 11:27:05 INFO SparkEnv: Registering OutputCommitCoordinator
23/04/06 11:27:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
23/04/06 11:27:05 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.31.10.73:4040
23/04/06 11:27:05 INFO Executor: Starting executor ID driver on host 172.31.10.73
23/04/06 11:27:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34973.
23/04/06 11:27:05 INFO NettyBlockTransferService: Server created on 172.31.10.73:34973
23/04/06 11:27:05 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
23/04/06 11:27:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.31.10.73, 34973, None)
23/04/06 11:27:05 INFO BlockManagerMasterEndpoint: Registering block manager 172.31.10.73:34973 with 434.4 MiB RAM, BlockManagerId(driver, 172.31.10.73, 34973, None)
23/04/06 11:27:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.31.10.73, 34973, None)
23/04/06 11:27:05 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.31.10.73, 34973, None)
